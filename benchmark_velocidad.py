"""
ðŸš€ Script de Benchmark - ComparaciÃ³n de Velocidad v2.0

Compara el rendimiento antes y despuÃ©s de las optimizaciones.
"""

import requests
import time
from datetime import datetime

BASE_URL = "http://localhost:8000"

# Preguntas de prueba
PREGUNTAS_TEST = [
    "Â¿QuÃ© es la geomecÃ¡nica?",
    "Â¿CuÃ¡les son los principales tipos de rocas?",
    "Explica quÃ© es la fortificaciÃ³n en minerÃ­a",
    "Â¿QuÃ© factores causan las caÃ­das de rocas?",
    "Resume los mÃ©todos de soporte del terreno"
]

def medir_tiempo(funcion, *args, **kwargs):
    """Mide el tiempo de ejecuciÃ³n de una funciÃ³n."""
    inicio = time.time()
    resultado = funcion(*args, **kwargs)
    fin = time.time()
    return resultado, fin - inicio


def hacer_pregunta(pregunta, categoria="geomecanica", formato="plain"):
    """Hace una pregunta al API."""
    response = requests.post(f"{BASE_URL}/ask", json={
        'question': pregunta,
        'category': categoria,
        'format': formato
    })
    return response


def ver_stats_cache():
    """Obtiene estadÃ­sticas del cachÃ©."""
    try:
        response = requests.get(f"{BASE_URL}/cache/stats")
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None


def limpiar_cache():
    """Limpia el cachÃ© de respuestas."""
    try:
        response = requests.delete(f"{BASE_URL}/cache/clear")
        if response.status_code == 200:
            print("âœ… CachÃ© limpiado")
    except:
        print("âš ï¸  No se pudo limpiar el cachÃ©")


def ejecutar_benchmark():
    """Ejecuta el benchmark completo."""
    print("\n" + "="*70)
    print("ðŸš€ BENCHMARK DE VELOCIDAD - Sistema RAG v2.0")
    print("="*70)
    
    # Limpiar cachÃ© antes de empezar
    print("\nðŸ“‹ PreparaciÃ³n:")
    limpiar_cache()
    
    # Test 1: Primera ejecuciÃ³n (SIN cachÃ©)
    print("\n" + "â”€"*70)
    print("ðŸ“Š TEST 1: Primera ejecuciÃ³n (SIN cachÃ©)")
    print("â”€"*70)
    
    tiempos_primera = []
    for i, pregunta in enumerate(PREGUNTAS_TEST, 1):
        print(f"\n{i}. Pregunta: '{pregunta[:50]}...'")
        _, tiempo = medir_tiempo(hacer_pregunta, pregunta)
        tiempos_primera.append(tiempo)
        print(f"   â±ï¸  Tiempo: {tiempo:.2f}s")
    
    promedio_primera = sum(tiempos_primera) / len(tiempos_primera)
    print(f"\nðŸ“ˆ Promedio SIN cachÃ©: {promedio_primera:.2f}s")
    
    # Ver estado del cachÃ©
    stats = ver_stats_cache()
    if stats:
        print(f"ðŸ’¾ Respuestas en cachÃ©: {stats['answer_cache_size']}/{stats['answer_cache_max']}")
    
    # Test 2: Segunda ejecuciÃ³n (CON cachÃ©)
    print("\n" + "â”€"*70)
    print("ðŸ“Š TEST 2: Segunda ejecuciÃ³n (CON cachÃ©)")
    print("â”€"*70)
    
    tiempos_segunda = []
    for i, pregunta in enumerate(PREGUNTAS_TEST, 1):
        print(f"\n{i}. Pregunta: '{pregunta[:50]}...'")
        _, tiempo = medir_tiempo(hacer_pregunta, pregunta)
        tiempos_segunda.append(tiempo)
        print(f"   âš¡ Tiempo: {tiempo:.3f}s")
    
    promedio_segunda = sum(tiempos_segunda) / len(tiempos_segunda)
    print(f"\nðŸ“ˆ Promedio CON cachÃ©: {promedio_segunda:.3f}s")
    
    # Calcular mejora
    mejora = promedio_primera / promedio_segunda
    print(f"\nðŸŽ¯ Mejora con cachÃ©: {mejora:.1f}x mÃ¡s rÃ¡pido")
    
    # Test 3: EstadÃ­sticas finales
    print("\n" + "â”€"*70)
    print("ðŸ“Š RESUMEN DE RENDIMIENTO")
    print("â”€"*70)
    
    print(f"\nâ±ï¸  VELOCIDAD:")
    print(f"   â€¢ Primera consulta (sin cachÃ©):  {promedio_primera:.2f}s")
    print(f"   â€¢ Consulta repetida (con cachÃ©): {promedio_segunda:.3f}s")
    print(f"   â€¢ Mejora:                        {mejora:.1f}x mÃ¡s rÃ¡pido")
    
    print(f"\nðŸ’° COSTOS ESTIMADOS (por consulta):")
    costo_primera = promedio_primera * 0.001  # EstimaciÃ³n aprox
    costo_segunda = 0.000  # CachÃ© es gratis
    print(f"   â€¢ Primera consulta:  ~${costo_primera:.4f}")
    print(f"   â€¢ Con cachÃ©:         ${costo_segunda:.4f} (Â¡GRATIS!)")
    
    print(f"\nðŸ’¾ CACHÃ‰:")
    if stats:
        print(f"   â€¢ TamaÃ±o actual:     {stats['answer_cache_size']}")
        print(f"   â€¢ Capacidad mÃ¡xima:  {stats['answer_cache_max']}")
        print(f"   â€¢ UtilizaciÃ³n:       {stats['answer_cache_size']/stats['answer_cache_max']*100:.1f}%")
    
    # Test 4: ComparaciÃ³n con estimaciones de v1.0
    print("\n" + "â”€"*70)
    print("ðŸ“Š COMPARACIÃ“N: v1.0 vs v2.0")
    print("â”€"*70)
    
    # Estimaciones de v1.0 (gpt-4, temp=1, k=3)
    tiempo_v1 = 10.0  # Estimado
    costo_v1 = 0.045  # Estimado por consulta
    
    print(f"\nðŸ“‰ VERSIÃ“N 1.0 (estimado):")
    print(f"   â€¢ Modelo:        gpt-4")
    print(f"   â€¢ Temperatura:   1")
    print(f"   â€¢ Documentos:    3")
    print(f"   â€¢ Tiempo:        ~{tiempo_v1:.1f}s")
    print(f"   â€¢ Costo:         ~${costo_v1:.3f}")
    
    print(f"\nðŸ“ˆ VERSIÃ“N 2.0 (medido):")
    print(f"   â€¢ Modelo:        gpt-4o-mini")
    print(f"   â€¢ Temperatura:   0")
    print(f"   â€¢ Documentos:    2 (MMR)")
    print(f"   â€¢ Tiempo:        ~{promedio_primera:.1f}s")
    print(f"   â€¢ Costo:         ~${costo_primera:.3f}")
    print(f"   â€¢ Con cachÃ©:     ~{promedio_segunda:.3f}s (${costo_segunda:.3f})")
    
    mejora_velocidad = tiempo_v1 / promedio_primera
    mejora_costo = ((costo_v1 - costo_primera) / costo_v1) * 100
    
    print(f"\nðŸŽ¯ MEJORAS GLOBALES:")
    print(f"   âš¡ Velocidad:     {mejora_velocidad:.1f}x mÃ¡s rÃ¡pido")
    print(f"   ðŸ’° Costo:         {mejora_costo:.1f}% mÃ¡s barato")
    print(f"   âš¡ Con cachÃ©:     {tiempo_v1/promedio_segunda:.0f}x mÃ¡s rÃ¡pido (Â¡GRATIS!)")
    
    # Test 5: Proyecciones de uso
    print("\n" + "â”€"*70)
    print("ðŸ“Š PROYECCIONES DE USO MENSUAL")
    print("â”€"*70)
    
    consultas_dia = 1000
    consultas_mes = consultas_dia * 30
    
    costo_mes_v1 = consultas_mes * costo_v1
    costo_mes_v2_sin_cache = consultas_mes * costo_primera
    costo_mes_v2_con_cache = consultas_mes * 0.3 * costo_primera  # 70% cachÃ©, 30% nuevas
    
    print(f"\nEscenario: {consultas_dia:,} consultas/dÃ­a ({consultas_mes:,}/mes)")
    print(f"\nðŸ’° COSTOS MENSUALES:")
    print(f"   â€¢ v1.0:                           ${costo_mes_v1:,.2f}")
    print(f"   â€¢ v2.0 (sin aprovechar cachÃ©):    ${costo_mes_v2_sin_cache:,.2f}")
    print(f"   â€¢ v2.0 (70% cachÃ©, 30% nuevas):   ${costo_mes_v2_con_cache:,.2f}")
    
    ahorro = costo_mes_v1 - costo_mes_v2_con_cache
    ahorro_pct = (ahorro / costo_mes_v1) * 100
    
    print(f"\nðŸ’µ AHORRO MENSUAL:")
    print(f"   â€¢ Cantidad:      ${ahorro:,.2f}")
    print(f"   â€¢ Porcentaje:    {ahorro_pct:.1f}%")
    print(f"   â€¢ Anual:         ${ahorro * 12:,.2f}")
    
    print("\n" + "="*70)
    print("âœ… BENCHMARK COMPLETADO")
    print("="*70)
    
    # Recomendaciones
    print("\nðŸ’¡ RECOMENDACIONES:")
    if promedio_primera > 3:
        print("   âš ï¸  Tiempo de primera consulta alto (>3s)")
        print("      â†’ Considera reducir chunk_size o k para mayor velocidad")
    else:
        print("   âœ… Tiempo de primera consulta Ã³ptimo (<3s)")
    
    if stats and stats['answer_cache_size'] < 10:
        print("   â„¹ï¸  Pocas respuestas en cachÃ©")
        print("      â†’ El cachÃ© serÃ¡ mÃ¡s efectivo con mÃ¡s uso")
    else:
        print("   âœ… CachÃ© funcionando correctamente")
    
    print(f"\nðŸ“… Benchmark ejecutado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()


if __name__ == "__main__":
    try:
        ejecutar_benchmark()
    except requests.exceptions.ConnectionError:
        print("\nâŒ Error: No se puede conectar a la API")
        print("   AsegÃºrate de que el servidor estÃ© corriendo:")
        print("   uvicorn main:app --reload")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Benchmark interrumpido por el usuario")
    except Exception as e:
        print(f"\nâŒ Error inesperado: {e}")
